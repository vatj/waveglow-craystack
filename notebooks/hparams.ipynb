{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveglow parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of flow blocks/composite layers in the model. Each flow is Invertible Convolution + Integer Coupling Layer to Wavenet\n",
    "hparams['n_flows'] = 16\n",
    "# Number of initial channels in invertible convolution\n",
    "hparams['n_group'] = 16\n",
    "# Number of flow layers between each channel reduction\n",
    "hparams['n_early_every'] = 4\n",
    "# Number of channels to shave from audio sample every n_early_every\n",
    "hparams['n_early_size'] = 4\n",
    "# Hidden Channels\n",
    "hparams[\"hidden_channels\"] = 256\n",
    "# Number of Dlogistic\n",
    "hparams['n_logistic_in_mixture'] = 10\n",
    "# Last log_scale \n",
    "hparams['last_log_scale'] = -6.5\n",
    "# Seed to set permutation layers\n",
    "hparams['seed'] = 235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavenet Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of composite layer in Wavenet acting first with separate Conv1D on audio and spectrogram\n",
    "# followed by sigmoid and tanh activations. Last comes a skip_layer\n",
    "hparams['n_layers'] = 8\n",
    "# Kernel size of the Wavenet convolution, no causality restriction\n",
    "hparams['kernel_size'] = 3\n",
    "# Number of hidden channels in Wavenet composite layers\n",
    "hparams['n_channels'] = 256\n",
    "# Only half of the audio sample channels go through wavenet.\n",
    "hparams['n_in_channels'] = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of audio samples from LJSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop audio samples to length pow(2, _) . Small samples of pow(2, _) (14 is about 10% of original sample length)\n",
    "hparams['segment_length'] = pow(2, 10)\n",
    "# Wav file sampling rate\n",
    "hparams['sample_rate'] = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machinery Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floating precision. \n",
    "hparams['ftype'] = tf.float32\n",
    "# Batch size for training\n",
    "hparams['train_batch_size'] = 24\n",
    "# Learning rate, set to range(1e-3, 1e-4) for Adam and 1.0 for AdaDelta. Learning rate scheduler not supported yet\n",
    "hparams['learning_rate'] = 1e-4\n",
    "# Number of epochs to iterate over. Might be replaced by a number of training step in the future\n",
    "hparams['epochs'] = 1000\n",
    "# Buffer size for shuffling\n",
    "hparams['buffer_size'] = 240\n",
    "# Optimizer, either Adam or AdaDelta. If AdaDelta, learning_rate = 1.0. \n",
    "# Added experimental tensorflow wrapper to support mixed precision and tf.float16\n",
    "hparams['optimizer'] = \"Adam\" \n",
    "# Enable mixed precision calculation. \n",
    "hparams['mixed_precision'] = False # Not fully implemented yet.\n",
    "# Enable learning rate decay\n",
    "hparams[\"learning_rate_decay\"] = False # Not implemented yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model every number of step\n",
    "hparams['save_model_every'] = 1000\n",
    "# Save audio samples every number of step\n",
    "hparams['save_audio_every'] = 5000\n",
    "# Try compression every number of step\n",
    "hparams['save_compression_every'] = 5000\n",
    "# Number of checkpoint files to keep\n",
    "hparams['max_to_keep'] = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Craystack Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size for compression tasks\n",
    "hparams['compress_batch_size'] = 1\n",
    "# zdim for craystack\n",
    "hparams['zdim'] = (hparams['segment_length'] // 4, 1)\n",
    "hparams['xdim'] = (hparams['segment_length'], 1)\n",
    "# Coding precision of the encoder. Value above 28 produce warning but necessary to rebalance buckets\n",
    "hparams['coding_prec'] = 31 \n",
    "# Bin precision for LogisticMixture_UnifBins codec. Necessary 16 since encoding np.int16\n",
    "hparams['bin_precision'] = 16 \n",
    "# Lower bound for LogisticMixture_UnifBins codec\n",
    "hparams['bin_lower_bound'] = -1.\n",
    "# Upper bound for LogisticMixture_UnifBins codec\n",
    "hparams['bin_upper_bound'] = 1.\n",
    "# Number of datapoint to compress. Higher value allows to offset the overhead associated to rANS encoder.\n",
    "# 10 samples for segment_length of pow(2, 14) takes roughly 1 hour on my cpu and ~16GB RAM\n",
    "hparams['n_compress_datapoint'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tfrecords files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data in n_shards tfrecords files\n",
    "hparams['n_shards'] = 12 \n",
    "# Number of excluded example from training set to generate audio samples at each epochs for quality assessment\n",
    "hparams['n_eval_samples'] = 20 \n",
    "# Number of excluded audio samples to run test on after training\n",
    "hparams['n_test_samples'] = 80\n",
    "# Training tfrecords common filename\n",
    "hparams['train_files'] = 'ljs_train'\n",
    "# Evaluation tfrecords filename\n",
    "hparams['eval_file'] = 'ljs_eval.tfrecords'\n",
    "# Test tfrecords filename\n",
    "hparams['test_file'] = 'ljs_test.tfrecords'\n",
    "# Long audio sample filename\n",
    "hparams['long_audio_file'] = 'ljs_long.tfrecords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common file name\n",
    "save_name = '{segment_length}c_craystack_seed={seed}_flows={n_flows}'.format(**hparams)\n",
    "# Machine Home Path\n",
    "hparams['base_path'] = os.path.join('/', 'home', 'victor', 'Projects', 'Github')\n",
    "# Raw data directory\n",
    "hparams['data_dir'] = os.path.join('/', 'home', 'victor', '.keras', 'datasets', 'LJSpeech-1.1')\n",
    "# Tfrecords directory.\n",
    "hparams['tfrecords_dir'] = os.path.join(hparams['base_path'], 'waveglow-craystack', 'data')\n",
    "# Log directory for tf.summary and tensorboard\n",
    "hparams['log_dir'] = os.path.join(hparams['base_path'], 'waveglow-compression', 'logs', save_name)\n",
    "# Checkpoint directory to save and restore model\n",
    "hparams['checkpoint_dir'] = os.path.join(hparams['base_path'], 'waveglow-compression', 'checkpoints', save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy or Not implemented\n",
    "# hparams['train_steps'] = 100  # Not implemented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waveglow-compression",
   "language": "python",
   "name": "waveglow-compression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
