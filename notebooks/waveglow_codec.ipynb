{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check Notebook (should be converted to test unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_dir, _ = os.path.split(os.getcwd())\n",
    "script_dir = os.path.join(root_dir, 'scripts')\n",
    "sys.path.append(script_dir)\n",
    "os.nice(15)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import craystack as cs\n",
    "from craystack.codecs import LogisticMixture_UnifBins, Codec\n",
    "import training_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Waveglow_codec(model, hparams):\n",
    "  \n",
    "  coding_prec = hparams['coding_prec']\n",
    "  bin_precision = hparams['bin_precision']\n",
    "  bin_lowerbound = hparams['bin_lower_bound']\n",
    "  bin_upperbound = hparams['bin_upper_bound']\n",
    "  \n",
    "  def WaveglowLogisticMixture(all_params, block):\n",
    "    return LogisticMixture_UnifBins(logit_probs=all_params[0], means=all_params[1], log_scales=all_params[2], \n",
    "                                    coding_prec=coding_prec, bin_prec=bin_precision, \n",
    "                                    bin_lb=bin_lowerbound, bin_ub=bin_upperbound)\n",
    "  \n",
    "  \n",
    "  def AutoRegressiveIDF(model, elem_codec):\n",
    "    \"\"\"\n",
    "    Codec for data from distributions which are calculated autoregressively.\n",
    "    That is, the data can be partitioned into n elements such that the\n",
    "    distribution/codec for an element is only known when all previous\n",
    "    elements are known. This is does not affect the push step, but does\n",
    "    affect the pop step, which must be done in sequence (so is slower).\n",
    "    elem_param_fn maps data to the params for the respective codecs.\n",
    "    elem_idxs defines the ordering over elements within data.\n",
    "    We assume that the indices within elem_idxs can also be used to index\n",
    "    the params from elem_param_fn. These indexed params are then used in\n",
    "    the elem_codec to actually code each element.\n",
    "    \"\"\"\n",
    "    def push(message, data):\n",
    "      encodable, all_params = model.infer_craystack(data)\n",
    "      for block in range(model.n_blocks + 1):\n",
    "        elem_params = all_params[block]\n",
    "        elem_push, _ = elem_codec(elem_params, block) # block potentially useless here but good to have the option\n",
    "        message = elem_push(message, encodable[block].astype('uint64'))\n",
    "      return message\n",
    "\n",
    "    def pop(message):\n",
    "      elem = None\n",
    "      for block in reversed(range(model.n_blocks + 1)):\n",
    "        data, all_params = model.generate_craystack(x=None if block + 1 > model.n_blocks else data, \n",
    "                                                    z=elem, block=block+1)\n",
    "        _, elem_pop = elem_codec(all_params=all_params, block=block)\n",
    "        message, elem = elem_pop(message)\n",
    "        \n",
    "      data, all_params = model.generate_craystack(x=data, z=elem, block=0)\n",
    "      return message, data\n",
    "  \n",
    "    return Codec(push, pop)\n",
    "\n",
    "  return AutoRegressiveIDF(model=model, elem_codec=WaveglowLogisticMixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_samples(model, hparams, step=tf.constant(0), decode=False):\n",
    "\n",
    "  model.set_compression()\n",
    "  \n",
    "  test_set = utils.load_training_files_tfrecords(\n",
    "    record_pattern=os.path.join(hparams['tfrecords_dir'], hparams['train_files'] + '*'))\n",
    "      \n",
    "  datapoints = list(test_set.unbatch().batch(\n",
    "    hparams['compress_batch_size']).take(hparams['n_compress_datapoint']))\n",
    "  \n",
    "  num_pixels = hparams['n_compress_datapoint'] * hparams['compress_batch_size'] * hparams['segment_length']\n",
    "  \n",
    "  ## Load Codec\n",
    "  waveglow_append, waveglow_pop = cs.repeat(Waveglow_codec(model=model, hparams=hparams), \n",
    "                                            hparams['n_compress_datapoint'])\n",
    "  \n",
    "  ## Encode\n",
    "  encode_t0 = time.time()\n",
    "  init_message = cs.empty_message(shape=(hparams['compress_batch_size'],\n",
    "                                         hparams['segment_length'] // 4))\n",
    "  \n",
    "  # Encode the audio samples\n",
    "  message = waveglow_append(init_message, datapoints)\n",
    "\n",
    "  flat_message = cs.flatten(message)\n",
    "  encode_t = time.time() - encode_t0\n",
    "\n",
    "  tf.print(\"All encoded in {:.2f}s.\".format(encode_t))\n",
    "\n",
    "  original_len = 16 * hparams['n_compress_datapoint'] * hparams['segment_length']\n",
    "  message_len = 32 * len(flat_message)\n",
    "  tf.print(\"Used {} bits.\".format(message_len))\n",
    "  tf.print(\"This is {:.2f} bits per pixel.\".format(message_len / num_pixels))\n",
    "  tf.print(\"Compression ratio : {:.2f}\".format(original_len / message_len))\n",
    "  \n",
    "  tf.summary.scalar(name='bits_per_dim', data= message_len / num_pixels, step=step)\n",
    "  tf.summary.scalar(name='compression_ratio', data=original_len / message_len, step=step)\n",
    "  \n",
    "  if decode:\n",
    "    ## Decode\n",
    "    decode_t0 = time.time()\n",
    "    message = cs.unflatten(flat_message, shape=(hparams['compress_batch_size'], \n",
    "                                                hparams['segment_length'] // 4))\n",
    "\n",
    "    message, datapoints_ = waveglow_pop(message)\n",
    "    decode_t = time.time() - decode_t0\n",
    "\n",
    "    print('All decoded in {:.2f}s.'.format(decode_t))\n",
    "    \n",
    "    datacompare = [data['wav'].numpy()[..., np.newaxis] for data in datapoints]\n",
    "    np.testing.assert_equal(datacompare, datapoints_)\n",
    "    np.testing.assert_equal(message, init_message)\n",
    "  \n",
    "  model.set_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "craystack",
   "language": "python",
   "name": "craystack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
